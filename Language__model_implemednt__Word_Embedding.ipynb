{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMMG1fYykGJHZoiPBjoDYq7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valid999/NLP-TensorFlow_Projects/blob/main/Language__model_implemednt__Word_Embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nIkX6XPTV6-b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ec96fdc-98df-4a3a-e0ce-3121b930b933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu\n",
            "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "### Libraries Used Tensorflow > 2.0 and keras\n",
        "!pip install tensorflow-gpu\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRaswTdxXrzR",
        "outputId": "8c3d6437-70bd-4527-86e9-3e510e531288"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Tensorflow > 2.0\n",
        "from tensorflow.keras.preprocessing.text import one_hot"
      ],
      "metadata": {
        "id": "3znS-EGiX7MS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Sentences\n",
        "\n",
        "sent = ['the glass of milk' ,\n",
        "        'the glass of juice' ,\n",
        "        'the cup of tea',\n",
        "        'I am a good boy',\n",
        "        'i am a good developer',\n",
        "        'understand the meaning of words',\n",
        "        'your videos are good'\n",
        "        ]"
      ],
      "metadata": {
        "id": "_bMD3t6HYFZs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wR2gne_Yhk3",
        "outputId": "72ab4281-1332-4b8b-8847-9993584a64c9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the glass of milk',\n",
              " 'the glass of juice',\n",
              " 'the cup of tea',\n",
              " 'I am a good boy',\n",
              " 'i am a good developer',\n",
              " 'understand the meaning of words',\n",
              " 'your videos are good']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Vocabulary size\n",
        "voc_size = 500"
      ],
      "metadata": {
        "id": "tfoMsVu6Yiir"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One Hot Representation"
      ],
      "metadata": {
        "id": "ThI-yCEAYn2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_repr = [one_hot(words , voc_size) for words in sent]\n",
        "print(onehot_repr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-jGkBYuYsFg",
        "outputId": "ffb203ae-4baa-49bf-ebf7-98c3ba8c74fa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[20, 39, 331, 393], [20, 39, 331, 232], [20, 142, 331, 442], [432, 134, 130, 296, 10], [432, 134, 130, 296, 481], [454, 20, 234, 331, 308], [202, 363, 116, 296]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Embedding Representation"
      ],
      "metadata": {
        "id": "RksRg4HoY9pC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "rnNi087eZDwL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "gwPDIo1mZVCr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Pre padding\n",
        "sent_length = 8\n",
        "embedded_docs = pad_sequences(onehot_repr , padding = 'pre' , maxlen = sent_length)\n",
        "print(embedded_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeT8fpVUZXTd",
        "outputId": "308ec56f-1977-4c1e-e075-8157d4e44d51"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0  20  39 331 393]\n",
            " [  0   0   0   0  20  39 331 232]\n",
            " [  0   0   0   0  20 142 331 442]\n",
            " [  0   0   0 432 134 130 296  10]\n",
            " [  0   0   0 432 134 130 296 481]\n",
            " [  0   0   0 454  20 234 331 308]\n",
            " [  0   0   0   0 202 363 116 296]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 10 feature dimensions\n",
        "dim = 10"
      ],
      "metadata": {
        "id": "-AHP5KzkZw5R"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(voc_size , 10 , input_length = sent_length))\n",
        "model.compile('adam' , 'mse')"
      ],
      "metadata": {
        "id": "-72hFEu9aFmC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGLVkABnaWcy",
        "outputId": "d0ef23c3-b1b3-4e24-db9b-b580c1b352f5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 8, 10)             5000      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5000 (19.53 KB)\n",
            "Trainable params: 5000 (19.53 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The glass of milk\n",
        "embedded_docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG37bCI3aWZb",
        "outputId": "b7815851-5ef7-4c64-c819-a483e9c41236"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,  20,  39, 331, 393], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(embedded_docs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgxXEL--aWXP",
        "outputId": "e2f61964-c8c8-4d5f-e963-3c9b167adcf9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 92ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.01589286, -0.02742937,  0.02218122,  0.02623929,  0.02291832,\n",
              "        -0.01258658,  0.02542507,  0.03733437, -0.0373497 ,  0.04536009],\n",
              "       [-0.01589286, -0.02742937,  0.02218122,  0.02623929,  0.02291832,\n",
              "        -0.01258658,  0.02542507,  0.03733437, -0.0373497 ,  0.04536009],\n",
              "       [-0.01589286, -0.02742937,  0.02218122,  0.02623929,  0.02291832,\n",
              "        -0.01258658,  0.02542507,  0.03733437, -0.0373497 ,  0.04536009],\n",
              "       [-0.01589286, -0.02742937,  0.02218122,  0.02623929,  0.02291832,\n",
              "        -0.01258658,  0.02542507,  0.03733437, -0.0373497 ,  0.04536009],\n",
              "       [-0.03794704,  0.01999393,  0.04419984, -0.03946738,  0.04127594,\n",
              "         0.0311825 , -0.00683515,  0.03725933,  0.04283459,  0.01024514],\n",
              "       [-0.01582485,  0.01586736,  0.03256248, -0.04603052,  0.01451811,\n",
              "         0.017889  ,  0.02000965,  0.04992077,  0.0409114 ,  0.01353646],\n",
              "       [ 0.02730007,  0.02362004, -0.01410924,  0.02722796, -0.02367629,\n",
              "        -0.02671101, -0.03708826, -0.03733739,  0.04740505, -0.0260379 ],\n",
              "       [ 0.04587575,  0.0308771 ,  0.0164214 , -0.0149316 , -0.00841385,\n",
              "        -0.00427538,  0.02837783, -0.0303327 ,  0.04718823,  0.01875066]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict(embedded_docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_2Xs-hKaWUb",
        "outputId": "8010f8dc-1302-4bff-d1bd-ca5729ea0b1d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 49ms/step\n",
            "[[[-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832\n",
            "   -0.01258658  0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            "  [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832\n",
            "   -0.01258658  0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            "  [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832\n",
            "   -0.01258658  0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            "  [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832\n",
            "   -0.01258658  0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            "  [-0.03794704  0.01999393  0.04419984 -0.03946738  0.04127594\n",
            "    0.0311825  -0.00683515  0.03725933  0.04283459  0.01024514]\n",
            "  [-0.01582485  0.01586736  0.03256248 -0.04603052  0.01451811\n",
            "    0.017889    0.02000965  0.04992077  0.0409114   0.01353646]\n",
            "  [ 0.02730007  0.02362004 -0.01410924  0.02722796 -0.02367629\n",
            "   -0.02671101 -0.03708826 -0.03733739  0.04740505 -0.0260379 ]\n",
            "  [ 0.04587575  0.0308771   0.0164214  -0.0149316  -0.00841385\n",
            "   -0.00427538  0.02837783 -0.0303327   0.04718823  0.01875066]]\n",
            "\n",
            " [[-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832\n",
            "   -0.01258658  0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            "  [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832\n",
            "   -0.01258658  0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            "  [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832\n",
            "   -0.01258658  0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            "  [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832\n",
            "   -0.01258658  0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            "  [-0.03794704  0.01999393  0.04419984 -0.03946738  0.04127594\n",
            "    0.0311825  -0.00683515  0.03725933  0.04283459  0.01024514]\n",
            "  [-0.01582485  0.01586736  0.03256248 -0.04603052  0.01451811\n",
            "    0.017889    0.02000965  0.04992077  0.0409114   0.01353646]\n",
            "  [ 0.02730007  0.02362004 -0.01410924  0.02722796 -0.02367629\n",
            "   -0.02671101 -0.03708826 -0.03733739  0.04740505 -0.0260379 ]\n",
            "  [-0.01679488 -0.02997395  0.01491583 -0.00670179 -0.04211224\n",
            "   -0.00389827  0.03572781 -0.04920869  0.04330971 -0.04008441]]\n",
            "\n",
            " [[-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832\n",
            "   -0.01258658  0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            "  [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832\n",
            "   -0.01258658  0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            "  [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832\n",
            "   -0.01258658  0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            "  [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832\n",
            "   -0.01258658  0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            "  [-0.03794704  0.01999393  0.04419984 -0.03946738  0.04127594\n",
            "    0.0311825  -0.00683515  0.03725933  0.04283459  0.01024514]\n",
            "  [-0.033819   -0.0356292  -0.03764064  0.00472765  0.01389556\n",
            "    0.04616263  0.00733595 -0.0222788   0.02729854  0.04751242]\n",
            "  [ 0.02730007  0.02362004 -0.01410924  0.02722796 -0.02367629\n",
            "   -0.02671101 -0.03708826 -0.03733739  0.04740505 -0.0260379 ]\n",
            "  [ 0.00662793 -0.04585856  0.00099788  0.01432225 -0.03618935\n",
            "   -0.01433057  0.01422862 -0.01069256 -0.04055003 -0.02684537]]\n",
            "\n",
            " [[-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832\n",
            "   -0.01258658  0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            "  [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832\n",
            "   -0.01258658  0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            "  [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832\n",
            "   -0.01258658  0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            "  [ 0.04988361  0.00767578 -0.01352511  0.02591662 -0.03012108\n",
            "   -0.00048231 -0.02361698 -0.0324674  -0.0050819  -0.04609426]\n",
            "  [ 0.04978986 -0.02485342  0.03614542  0.04063315 -0.03942404\n",
            "   -0.02470752  0.03862477  0.02854769  0.00142769 -0.00382511]\n",
            "  [-0.00624908 -0.03687242 -0.02192396  0.04553698  0.00575771\n",
            "    0.01741678 -0.02333404  0.02188969  0.03055686 -0.04775123]\n",
            "  [-0.02209767  0.02961555  0.00606761 -0.02846549  0.04646314\n",
            "    0.03612899  0.01630637  0.03190694  0.00324307 -0.00095029]\n",
            "  [ 0.01871786  0.03539846 -0.0164511   0.01060238 -0.00759317\n",
            "   -0.04462509 -0.01565222 -0.02371301 -0.02780383 -0.04373522]]\n",
            "\n",
            " [[-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832\n",
            "   -0.01258658  0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            "  [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832\n",
            "   -0.01258658  0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            "  [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832\n",
            "   -0.01258658  0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            "  [ 0.04988361  0.00767578 -0.01352511  0.02591662 -0.03012108\n",
            "   -0.00048231 -0.02361698 -0.0324674  -0.0050819  -0.04609426]\n",
            "  [ 0.04978986 -0.02485342  0.03614542  0.04063315 -0.03942404\n",
            "   -0.02470752  0.03862477  0.02854769  0.00142769 -0.00382511]\n",
            "  [-0.00624908 -0.03687242 -0.02192396  0.04553698  0.00575771\n",
            "    0.01741678 -0.02333404  0.02188969  0.03055686 -0.04775123]\n",
            "  [-0.02209767  0.02961555  0.00606761 -0.02846549  0.04646314\n",
            "    0.03612899  0.01630637  0.03190694  0.00324307 -0.00095029]\n",
            "  [-0.03796598 -0.02125346 -0.03600525  0.00493323  0.03589659\n",
            "    0.04284251  0.03538958 -0.00433142 -0.03060758  0.02333958]]\n",
            "\n",
            " [[-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832\n",
            "   -0.01258658  0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            "  [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832\n",
            "   -0.01258658  0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            "  [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832\n",
            "   -0.01258658  0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            "  [-0.01058158  0.03401352  0.04265741  0.03158816  0.00341312\n",
            "    0.01080523  0.03178729 -0.00889871  0.04816082 -0.02750696]\n",
            "  [-0.03794704  0.01999393  0.04419984 -0.03946738  0.04127594\n",
            "    0.0311825  -0.00683515  0.03725933  0.04283459  0.01024514]\n",
            "  [-0.02312948  0.03481347 -0.02881641 -0.02664827  0.03428913\n",
            "    0.04025849 -0.01716814 -0.01542129 -0.02587029  0.03517782]\n",
            "  [ 0.02730007  0.02362004 -0.01410924  0.02722796 -0.02367629\n",
            "   -0.02671101 -0.03708826 -0.03733739  0.04740505 -0.0260379 ]\n",
            "  [-0.03628391 -0.02881115 -0.00562171  0.03323067 -0.04226078\n",
            "   -0.04091739  0.00375702  0.0243074  -0.03922074  0.02507278]]\n",
            "\n",
            " [[-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832\n",
            "   -0.01258658  0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            "  [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832\n",
            "   -0.01258658  0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            "  [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832\n",
            "   -0.01258658  0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            "  [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832\n",
            "   -0.01258658  0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            "  [-0.04859799 -0.04398144  0.01495467  0.00028095 -0.02032699\n",
            "   -0.03433077 -0.03142643  0.00294075  0.01255448 -0.04641598]\n",
            "  [ 0.00828954  0.03783984 -0.02473372  0.03757571 -0.02766677\n",
            "    0.03836813 -0.01381276  0.01555324  0.00419589  0.02429282]\n",
            "  [ 0.00650362  0.02701573  0.00399116  0.03149002  0.00409738\n",
            "    0.01709545  0.02380154 -0.02146307 -0.01997953  0.01388976]\n",
            "  [-0.02209767  0.02961555  0.00606761 -0.02846549  0.04646314\n",
            "    0.03612899  0.01630637  0.03190694  0.00324307 -0.00095029]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IJOHrmvaWM0",
        "outputId": "ab8bf6fe-1059-43d4-f303-663b797b704c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,  20,  39, 331, 393], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict(embedded_docs)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mybbU4bGbjPj",
        "outputId": "433e6754-44ca-401c-d507-2cdaaa5ebd32"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "[[-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832 -0.01258658\n",
            "   0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            " [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832 -0.01258658\n",
            "   0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            " [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832 -0.01258658\n",
            "   0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            " [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832 -0.01258658\n",
            "   0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            " [-0.03794704  0.01999393  0.04419984 -0.03946738  0.04127594  0.0311825\n",
            "  -0.00683515  0.03725933  0.04283459  0.01024514]\n",
            " [-0.01582485  0.01586736  0.03256248 -0.04603052  0.01451811  0.017889\n",
            "   0.02000965  0.04992077  0.0409114   0.01353646]\n",
            " [ 0.02730007  0.02362004 -0.01410924  0.02722796 -0.02367629 -0.02671101\n",
            "  -0.03708826 -0.03733739  0.04740505 -0.0260379 ]\n",
            " [ 0.04587575  0.0308771   0.0164214  -0.0149316  -0.00841385 -0.00427538\n",
            "   0.02837783 -0.0303327   0.04718823  0.01875066]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict(embedded_docs)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLOirE4zbpeH",
        "outputId": "f3803b7d-6a75-46f0-a1e2-08c12d598e90"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "[[-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832 -0.01258658\n",
            "   0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            " [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832 -0.01258658\n",
            "   0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            " [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832 -0.01258658\n",
            "   0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            " [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832 -0.01258658\n",
            "   0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            " [-0.03794704  0.01999393  0.04419984 -0.03946738  0.04127594  0.0311825\n",
            "  -0.00683515  0.03725933  0.04283459  0.01024514]\n",
            " [-0.01582485  0.01586736  0.03256248 -0.04603052  0.01451811  0.017889\n",
            "   0.02000965  0.04992077  0.0409114   0.01353646]\n",
            " [ 0.02730007  0.02362004 -0.01410924  0.02722796 -0.02367629 -0.02671101\n",
            "  -0.03708826 -0.03733739  0.04740505 -0.0260379 ]\n",
            " [ 0.04587575  0.0308771   0.0164214  -0.0149316  -0.00841385 -0.00427538\n",
            "   0.02837783 -0.0303327   0.04718823  0.01875066]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment for the"
      ],
      "metadata": {
        "id": "an4AIgq0cA1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Assignment\n",
        "\n",
        "task=[\"The world is a better place\",\n",
        "      \"Marvel series is my favourite movie\",\n",
        "      \"I like DC movies\",\n",
        "      \"the cat is eating the food\",\n",
        "      \"Tom and Jerry is my favourite movie\",\n",
        "      \"Python is my favourite programming language\"\n",
        "      ]"
      ],
      "metadata": {
        "id": "aELOVlb7b0vc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One hot"
      ],
      "metadata": {
        "id": "Pa-q7G7yb4e0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_repr = [one_hot(words , voc_size) for words in task]\n",
        "print(onehot_repr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA7YxjC3cJsR",
        "outputId": "0f747418-f459-48b3-a2bc-8de5b2c0e5aa"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[20, 179, 288, 130, 231, 485], [388, 15, 288, 90, 456, 256], [432, 104, 80, 428], [20, 295, 288, 6, 20, 37], [443, 79, 77, 288, 90, 456, 256], [430, 288, 90, 456, 16, 201]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Pre padding\n",
        "sent_length = 8\n",
        "embedded_docs_task = pad_sequences(onehot_repr , padding = 'post' , maxlen = sent_length)\n",
        "print(embedded_docs_task)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWSj8DKUcJov",
        "outputId": "f6531de3-ef9d-421f-abc7-97ab0e946734"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 20 179 288 130 231 485   0   0]\n",
            " [388  15 288  90 456 256   0   0]\n",
            " [432 104  80 428   0   0   0   0]\n",
            " [ 20 295 288   6  20  37   0   0]\n",
            " [443  79  77 288  90 456 256   0]\n",
            " [430 288  90 456  16 201   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict(embedded_docs_task[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPnPMHhtcJmD",
        "outputId": "3d697fa1-65f8-498a-b58a-b669d6378b12"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "[[-0.03794704  0.01999393  0.04419984 -0.03946738  0.04127594  0.0311825\n",
            "  -0.00683515  0.03725933  0.04283459  0.01024514]\n",
            " [ 0.04691513  0.03599203 -0.01449164 -0.04928589 -0.02641084  0.0440059\n",
            "  -0.03178389  0.03351523  0.02897276 -0.02511761]\n",
            " [ 0.02991792  0.01596861  0.01886922  0.03939315 -0.00708335 -0.01401179\n",
            "   0.02995812 -0.04264634 -0.0011536   0.01760424]\n",
            " [-0.00624908 -0.03687242 -0.02192396  0.04553698  0.00575771  0.01741678\n",
            "  -0.02333404  0.02188969  0.03055686 -0.04775123]\n",
            " [ 0.04984225  0.0332675  -0.03533296  0.04959798 -0.03447503 -0.00732932\n",
            "   0.00358033  0.03471655  0.02600602  0.00434582]\n",
            " [ 0.01757472  0.04102984 -0.02626623  0.04863584  0.02837977  0.03924957\n",
            "   0.0188706   0.02920728 -0.036645    0.02019585]\n",
            " [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832 -0.01258658\n",
            "   0.02542507  0.03733437 -0.0373497   0.04536009]\n",
            " [-0.01589286 -0.02742937  0.02218122  0.02623929  0.02291832 -0.01258658\n",
            "   0.02542507  0.03733437 -0.0373497   0.04536009]]\n"
          ]
        }
      ]
    }
  ]
}